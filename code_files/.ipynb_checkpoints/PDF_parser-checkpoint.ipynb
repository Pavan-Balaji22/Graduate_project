{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk as nltk\n",
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import torch\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_number(text):\n",
    "    text = re.sub(r'[^0-9]',\"\",text)\n",
    "    if len(text) > 0:\n",
    "        return int(text)\n",
    "    else:\n",
    "        return 0\n",
    "def load_cvs(cdir):\n",
    "    '''\n",
    "        Function to load all the cvs from a folder.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cdir - String indicating the directory where Cvs are present\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        cv_s - list of document objects by PyMuPDF\n",
    "    '''\n",
    "    path = os.getcwd() + \"\\\\\" + cdir\n",
    "    CV_folders = os.listdir(path)\n",
    "    cv_s = {}\n",
    "    for i in CV_folders:\n",
    "        folder_path = path + \"\\\\\" + i\n",
    "        files = os.listdir(folder_path)\n",
    "        for j in files:\n",
    "            if re.search(\".pdf\",j) is not None:\n",
    "                name = re.sub(\".pdf\",\"\",j)\n",
    "                file = fitz.open(folder_path+\"\\\\\"+j)\n",
    "                cv = doc_to_txt(file)\n",
    "                cv_s[name]={\"CV\":cv,\"Department\": i,\"n_pages\":file.page_count}\n",
    "                file.close()\n",
    "            \n",
    "    return cv_s\n",
    "\n",
    "def process_text(up_text):\n",
    "    '''\n",
    "        Function to process the extracted text.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        up_text - unprocessed text\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        processed_text -  processed text\n",
    "    '''\n",
    "    processed_text = re.sub(r'\\n (?!=\\w)',\"\",up_text)\n",
    "    processed_text = re.sub(r'\\n\\d{1} (?!=\\d)',\"\",processed_text)\n",
    "    processed_text = re.sub(r'\\n\\d{1} (?!=\\d)',\"\",processed_text)\n",
    "#     processed_text = re.sub(r'\\d{1} (?!=\\w)',\"\",processed_text)\n",
    "    processed_text = re.sub(r'[_]',\"\",processed_text)\n",
    "    processed_text = re.sub(r'[•]',\"\",processed_text)\n",
    "    return processed_text\n",
    "    \n",
    "\n",
    "def extract_text(document):\n",
    "    '''\n",
    "        Function to extract and process text from documents pages.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        document - A documents object containing CV\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        txt - text extracted from the documents object\n",
    "    '''\n",
    "    n_pages = document.page_count\n",
    "    txt = \"\"\n",
    "    for i in range(n_pages):\n",
    "        txt = txt+\" \"+document[i].get_text(\"text\",flags = 1)\n",
    "        txt = process_text(txt)\n",
    "    return txt\n",
    "    \n",
    "\n",
    "def doc_to_txt(CV_objects):\n",
    "    '''\n",
    "        Function to convert the PyMuPDF document objects to processed plain text data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        CV_objects - Document objects containing CVs\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        CV_objects- returns the object but each CV as a string  \n",
    "    '''\n",
    "    \n",
    "    CV_objects = extract_text(CV_objects)\n",
    "    return CV_objects\n",
    "\n",
    "def extract_req_data(original_data):\n",
    "    req_data = original_data.copy()\n",
    "    awards = list()\n",
    "    n_events = list()\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "    n = 0\n",
    "    for i in req_data[\"CV\"]:\n",
    "        doc = nlp(i)\n",
    "        entities = list()\n",
    "        labels = list()\n",
    "        for ent in doc.ents:\n",
    "            entities.append(ent.text)\n",
    "            labels.append(ent.label_)\n",
    "        temp = pd.DataFrame(np.c_[entities,labels],columns=[\"Entity\",\"Label\"])\n",
    "        print(req_data[\"Name\"][n])\n",
    "        awards.append(temp[temp[\"Label\"] == \"MONEY\"][\"Entity\"].apply(text_to_number).sum())\n",
    "        if \"EVENT\" in temp[\"Label\"].unique():\n",
    "            n_events.append(temp[\"Label\"].value_counts()[\"EVENT\"])\n",
    "        else:\n",
    "             n_events.append(0)\n",
    "        n = n + 1\n",
    "        del doc \n",
    "        torch.cuda.empty_cache() \n",
    "    \n",
    "    req_data[\"Awards\"] = awards\n",
    "    req_data[\"No of Event and Conferences\"]= n_events\n",
    "    return req_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_objs =  load_cvs(\"Public_CVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(cv_objs,index=None).T\n",
    "data.reset_index(inplace=True)\n",
    "data.columns = [\"Name\",\"CV\",\"Department\",\"PageCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json(\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexandra Martynova-Van Kley\n",
      "Ashley Elias\n",
      "BARRY G. ROBINSON\n",
      "BRIAN BECKAGE \n",
      "CARMEN G. MONTAÑA-SCHALK\n",
      "Caroline (Lina) Lund Dahlberg\n",
      "CHRISTOPHER LEONARD BRETT\n",
      "DANIEL J. BENNETT\n",
      "DENIS A. LAROCHELLE\n",
      "DENNIS A. GRAVATT\n",
      "Dior R. Kelley\n",
      "Easton R. White\n",
      "Eric Stabb\n",
      "Heidi J Gill Super\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JASON N. BRUCK\n",
      "JENNIFER M. BHATNAGAR\n",
      "John J. Ewel\n",
      "John M. Schmitt\n",
      "JOHN SAKULICH\n",
      "JOSEPH PETER MONTOYA\n",
      "Kimberly L. Mowry\n",
      "LAURA J. OLSEN\n",
      "Lindsay M. Porter\n",
      "Matthew A. Kwiatkowsk\n",
      "Michael E. Burns\n",
      "Michael I. Coates\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'EVENT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EVENT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-311a23746f77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreq_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_req_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-4c4f2771c3a9>\u001b[0m in \u001b[0;36mextract_req_data\u001b[1;34m(original_data)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mawards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Label\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"MONEY\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Entity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mn_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"EVENT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EVENT'"
     ]
    }
   ],
   "source": [
    "req_data = extract_req_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data[\"Name\"] == 'Curtis Berlinguette'][\"CV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cb3f3e8ce048e99421004f2445a6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/res…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 15:12:57 INFO: Downloading these customized packages for language: en (English)...\n",
      "===============================\n",
      "| Processor       | Package   |\n",
      "-------------------------------\n",
      "| ner             | ontonotes |\n",
      "| backward_charlm | 1billion  |\n",
      "| forward_charlm  | 1billion  |\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 15:12:58 INFO: File exists: C:\\Users\\Pavan Balaji Kumar\\stanza_resources\\en\\ner\\ontonotes.pt.\n",
      "2022-04-04 15:12:58 INFO: File exists: C:\\Users\\Pavan Balaji Kumar\\stanza_resources\\en\\backward_charlm\\1billion.pt.\n",
      "2022-04-04 15:12:58 INFO: File exists: C:\\Users\\Pavan Balaji Kumar\\stanza_resources\\en\\forward_charlm\\1billion.pt.\n",
      "2022-04-04 15:12:58 INFO: Finished downloading models and saved to C:\\Users\\Pavan Balaji Kumar\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download(lang=\"en\",package=\"OntoNotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 18:49:27 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-04-04 18:49:27 INFO: Use device: gpu\n",
      "2022-04-04 18:49:27 INFO: Loading: tokenize\n",
      "2022-04-04 18:49:29 INFO: Loading: ner\n",
      "2022-04-04 18:49:30 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "snlp = stanza.Pipeline(lang='en',package=\"Default\",processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = snlp(a[45])\n",
    "# print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents if ent.type == \"MONEY\"], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del snlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245366784\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.caching_allocator_delete())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = list()\n",
    "labels = list()\n",
    "for ent in doc.ents:\n",
    "    entities.append(ent.text)\n",
    "    labels.append(ent.label_)\n",
    "temp = pd.DataFrame(np.c_[entities,labels],columns=[\"Entity\",\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PERSON', 'ORG', 'GPE', 'DATE', 'CARDINAL', 'WORK_OF_ART', 'EVENT',\n",
       "       'MONEY', 'PERCENT'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "doc = nlp(a[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
